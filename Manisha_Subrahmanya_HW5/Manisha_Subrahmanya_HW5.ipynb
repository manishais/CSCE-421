import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import pandas as pd
from sklearn.metrics import f1_score
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
# Constants
BATCH_SIZE = 32
EPOCHS = 20
LEARNING_RATE = 0.0005
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Load and normalize data
x_train_wr = np.load('x_train_wr.npy') / 255.0
x_train_sp = np.load('x_train_sp.npy')
x_train_sp /= np.max(np.abs(x_train_sp))
y_train = pd.read_csv('y_train.csv').iloc[:, 1].values
x_test_wr = np.load('x_test_wr.npy') / 255.0
x_test_sp = np.load('x_test_sp.npy')
x_test_sp /= np.max(np.abs(x_test_sp))

# Convert to PyTorch tensors
x_train_wr = torch.tensor(x_train_wr.reshape((-1, 1, 28, 28)), dtype=torch.float32)
x_train_sp = torch.tensor(x_train_sp[:, np.newaxis, :], dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.long)

# Class weights for imbalance handling
class_weights = compute_class_weight('balanced', classes=np.unique(y_train.numpy()), y=y_train.numpy())
class_weights = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)

# Split training data for validation
x_train_wr_train, x_train_wr_val, x_train_sp_train, x_train_sp_val, y_train_train, y_train_val = train_test_split(
    x_train_wr, x_train_sp, y_train, test_size=0.2, random_state=42)

# Data loaders
train_dataset = TensorDataset(x_train_wr_train, x_train_sp_train, y_train_train)
train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)

val_dataset = TensorDataset(x_train_wr_val, x_train_sp_val, y_train_val)
val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)
# Define the model with Batch Normalization and Dropout
class MultiModalNet(nn.Module):
    def __init__(self):
        super(MultiModalNet, self).__init__()
        # Visual pathway
        self.visual_model = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Dropout(0.5),
            nn.Linear(64 * 7 * 7, 128),
            nn.ReLU()
        )
        # Audio pathway
        self.audio_model = nn.Sequential(
            nn.Conv1d(1, 32, 3, padding=1),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.MaxPool1d(2),
            nn.Conv1d(32, 64, 3, padding=1),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.MaxPool1d(2),
            nn.Flatten(),
            nn.Dropout(0.5),
            nn.Linear(64 * (x_train_sp_train.shape[2] // 4), 128),
            nn.ReLU()
        )
        # Classifier
        self.classifier = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, 10)
        )

    def forward(self, x_wr, x_sp):
        visual_features = self.visual_model(x_wr)
        audio_features = self.audio_model(x_sp)
        combined_features = torch.cat((visual_features, audio_features), dim=1)
        output = self.classifier(combined_features)
        return output

model = MultiModalNet().to(DEVICE)
criterion = nn.CrossEntropyLoss(weight=class_weights)
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
# Training loop
model.train()
for epoch in range(EPOCHS):
    model.train()
    for x_wr, x_sp, labels in train_loader:
        x_wr, x_sp, labels = x_wr.to(DEVICE), x_sp.to(DEVICE), labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(x_wr, x_sp)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

    # Validation step for F1 score
    model.eval()
    all_preds, all_labels = [], []
    with torch.no_grad():
        for x_wr, x_sp, labels in val_loader:
            x_wr, x_sp, labels = x_wr.to(DEVICE), x_sp.to(DEVICE), labels.to(DEVICE)
            outputs = model(x_wr, x_sp)
            _, predicted = torch.max(outputs, 1)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    val_f1 = f1_score(all_labels, all_preds, average='macro')
    print(f'Epoch {epoch+1}: Validation F1 Score: {val_f1:.4f}')

# Prepare and predict on test data
x_test_wr = torch.tensor(x_test_wr.reshape((-1, 1, 28, 28)), dtype=torch.float32).to(DEVICE)
x_test_sp = torch.tensor(x_test_sp[:, np.newaxis, :], dtype=torch.float32).to(DEVICE)
model.eval()
with torch.no_grad():
    outputs = model(x_test_wr, x_test_sp)
    _, predicted_labels = torch.max(outputs, 1)
    predicted_labels = predicted_labels.cpu().numpy()

# Save predictions to CSV
submission_df = pd.DataFrame({
    'row_id': np.arange(len(predicted_labels)),
    'label': predicted_labels
})
submission_df.to_csv('submissions.csv', index=False)
print("Predictions saved to 'submissions.csv'.")
