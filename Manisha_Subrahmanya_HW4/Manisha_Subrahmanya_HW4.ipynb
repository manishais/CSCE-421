import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
from torch.utils.data.sampler import SubsetRandomSampler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.nn.functional as F
import pandas as pd
# loading data
data_train = np.load('data_train.npy')
labels_train = np.load('labels_train.npy')
data_test = np.load('data_test.npy')
# PART A
class MNISTDataset(Dataset):
    def __init__(self, images, labels=None, transform=None):       # a method to initialize a new instance of the MNISTDataset
        self.images = images
        self.labels = labels
        self.transform = transform

    def __len__(self):         # a method to return the number of images in the dataset
        return len(self.images)

    def __getitem__(self, idx):       # a method to get the image and label at a specific index
        image = self.images[idx].reshape(30, 30).astype('float32')
        label = self.labels[idx]
        if self.transform:
            image = self.transform(image)
        return image, label

def create_data_loaders(data, labels, batch_size=64, validation_split=0.2, transform=None):
    # Define the dataset
    dataset = MNISTDataset(data, labels, transform=transform)
    
    # Split the dataset into training and validation
    val_size = int(len(dataset) * validation_split)
    train_size = len(dataset) - val_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    # Create data loaders
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size)
    
    return train_loader, val_loader

# Define a simple transform to convert numpy images to torch tensors
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Create the data loaders with a specified batch size and validation split
batch_size = 64
validation_split = 0.2
train_loader, val_loader = create_data_loaders(data_train, labels_train, batch_size, validation_split, transform)

# Just to check, we print out the number of batches in the training and validation loaders
len(train_loader), len(val_loader)
# The code defines a custom dataset and data loaders for training a model on image classification tasks. The MNISTDataset class intializes with 
# images and labels, and transforms, handling image reshaping and preprocessing. The create_data_loaders function splits the dataset into training and 
# validation subsets based on a given percentage, facilitating model generalization by evaluating on varied data. It creates DataLoader instances to 
# manage batching and shuffeling of data. The transform pipeline includes converting images to tensors and normalizing them, crucial for model 
# convergence. This setup streamlines the training process, optimizing data handling and model performance.
# PART B
def visualize_samples(data, labels):
    # Find indexes of the first occurrence of each digit
    unique_digits, indexes = np.unique(labels, return_index=True)
    fig, axs = plt.subplots(1, len(unique_digits), figsize=(15, 2))
    
    for digit, idx, ax in zip(unique_digits, indexes, axs):
        image = data[idx].reshape(28, 28)
        ax.imshow(image, cmap='gray')
        ax.set_title(f'Digit: {digit}')
        ax.axis('off')
    
    plt.show()

def count_samples_per_digit(labels):
    unique, counts = np.unique(labels, return_counts=True)
    return dict(zip(unique, counts))

# Visualize one example per digit
visualize_samples(data_train, labels_train)

# Count the number of samples per digit
samples_per_digit = count_samples_per_digit(labels_train)
samples_per_digit
# This section includes two functions designed to analyze and visualize a dataset of digit images. The visualize_samples function identifies and 
# displays one image for each unique digit in the dataset, using np.unique to find the first occurrence of each digit and imshow for visualization. 
# This helps in visually verifying the diversity and  correctness of the data. The count_samples_per_digit function counts the occurrences of each 
# digit using np.unique, returning a dictionary mapping each digit to its count, which is crucial for understanding sample distribution and ensuring 
# dataset balance.
# The dataset is relatively balanced. The range shows that the least common digit appears 5421 times and the most common digit appears 6742 times. 
# The average count for each digit is 6000. The standard deviation is 322.08. With this information, one can determine that the dataset is 
# relatively balanced.
# PART C
# Split the data and labels into training and validation sets (80% training, 20% validation)
data_train_split, data_val_split, labels_train_split, labels_val_split = train_test_split(
    data_train, labels_train, test_size=0.2, random_state=42, stratify=labels_train)
# The code splits data into training and validation sets (80% and 20%, respectively), 
# ensuring balanced class representation
# PART D
# Define the CNN architecture
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)
        self.fc1 = nn.Linear(64 * 7 * 7, 1024)
        self.fc2 = nn.Linear(1024, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 7 * 7)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Transform and DataLoader setup
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# def create_data_loaders(data, labels, batch_size=64, validation_split=0.2, transform=None):
#     dataset = MNISTDataset(data, labels, transform=transform)
#     val_size = int(len(dataset) * validation_split)
#     train_size = len(dataset) - val_size
#     train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
#     val_loader = DataLoader(val_dataset, batch_size=batch_size)
#     return train_loader, val_loader

train_loader, val_loader = create_data_loaders(data_train, labels_train, batch_size=64, validation_split=0.2, transform=transform)

# Initialize the network and optimizer
model = SimpleCNN()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
loss_function = nn.CrossEntropyLoss()

# Training loop
num_epochs = 3
for epoch in range(num_epochs):
    model.train()
    for images, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_function(outputs, labels)
        loss.backward()
        optimizer.step()
    print(f'Epoch {epoch+1}, Loss: {loss.item()}')

# Validation loop
def calculate_accuracy(model, data_loader):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in data_loader:
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    return accuracy

validation_accuracy = calculate_accuracy(model, val_loader)
print(f'Validation Accuracy: {validation_accuracy}%')

# This section defines a simple convolutional neural network (CNN) for image classification and sets up a training and validation process. The CNN, 
# SimpleCNN, includes two convolutional layers and two fully connected layers, tailored for feature extraction and classification tasks, respectively. 
# The dataset is preprocessed with standard normalization and converted to tensors. Data loaders manage batching and shuffling of training and validation 
# splits. Training involves running epochs, computing losses, and backpropagating errors. Validation measures model accuracy by comparing predictions 
# against true labels. This structured approach, with a focus on model training and validation, aims to optimize classification performance on image data.
# PART G
# Saving the model's state dictionary
torch.save(model.state_dict(), 'best_model.pth')
# Saving to a specific folder
torch.save(model.state_dict(), 'best_model.pth')

model = SimpleCNN()  # Ensure SimpleCNN is defined
model.load_state_dict(torch.load('best_model.pth'))
model.eval()

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

predictions = []
with torch.no_grad():
    for image in data_test:
        image = image.reshape(28, 28).astype('float32')
        image = transform(image)
        image = image.unsqueeze(0)  # Add batch dimension
        output = model(image)
        pred = output.argmax(dim=1, keepdim=True)
        predictions.append(pred.item())

predictions_df = pd.DataFrame(predictions, columns=['Predictions'])
predictions_df.to_csv('Manisha_Subrahmanya_Preds.csv', index=False)

print("saved")
# This section handles the inference and result storage for a trained CNN model on new data, specifically the MNIST test set. The model's parameters 
# are saved to disk, then reloaded into a newly instantiated model to ensure predictions use the trained weights. Images from the test dataset are 
# individually processed by reshaping, normalizing, and converting to tensorsâ€”necessary steps for compatibility with the trained model. Each image is 
# evaluated in isolation (hence the batch dimension addition), and the predicted class is determined. Predictions are collected, stored in a DataFrame,
# and saved to a CSV file, effectively documenting the model's performance on unseen data.
