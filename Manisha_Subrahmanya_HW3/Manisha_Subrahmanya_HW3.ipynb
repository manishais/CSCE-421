import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
import numpy as np
import matplotlib.pyplot as plt
# load the datasets
train_data = pd.read_csv('data_train-4.csv')
test_data = pd.read_csv('data_test-3.csv')
# PART A
# create a binary label based on the median of chance of admit
medianAdmitChance = train_data['Chance of Admit '].median()
train_data['Admit_Binary'] = (train_data['Chance of Admit '] > medianAdmitChance).astype(int)

# drop the original chance of admit column 
train_data.drop('Chance of Admit ', axis=1, inplace=True)

# split the data into training and validation sets (80-20 split)
X = train_data.drop(['Admit_Binary'], axis=1)
y = train_data['Admit_Binary']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
# PART B
# initialize SVM models with different kernels
linear = SVC(kernel='linear')
rbf = SVC(kernel='rbf')
poly = SVC(kernel='poly', degree=3)

models = [linear, rbf, poly]
models
# PART C
feature_combinations = [
    ['CGPA', 'SOP'],
    ['CGPA', 'GRE Score'],
    ['SOP', 'LOR '],
    ['LOR ', 'GRE Score']
]

# train each model with each feature combination and store their scores
trainingScores = {}
validationScores = {}

for model in models:
    model_name = type(model).__name__ + "-" + model.kernel
    trainingScores[model_name] = []
    validationScores[model_name] = []
    
    for features in feature_combinations:
        # train model
        model.fit(X_train[features], y_train)
        
        # evaluate on training and validation sets
        trainScore = model.score(X_train[features], y_train)
        validScore = model.score(X_val[features], y_val)
        
        # store scores
        trainingScores[model_name].append(trainScore)
        validationScores[model_name].append(validScore)

trainingScores, validationScores
# PART D
# retrieve detailed support vector information for each SVM model and feature combination
support_vectors = {}

for kernel, model_dict in {'Linear': linear, 'RBF': rbf, 'Poly3': poly}.items():
    support_vectors[kernel] = {}
    for i, features in enumerate(feature_combinations):
        model = model_dict
        X_train_ = X_train[features]
        model.fit(X_train_, y_train)
        n_vectors = model.n_support_
        support_vectors[kernel][f'Combination {i+1}'] = {
            'Total Support Vectors': model.support_vectors_.shape[0],
            'Support Vectors by Class': n_vectors,
            'Support Vector Indices': model.support_
        }

support_vectors
# A support vector is a data point that is closes to the hyperplane. They are critical
# because they directly influence the position and orientation of the hyperplane i.e.
# determine the decision boundary between different classes in the feature space.

# Linear Kernel SVM:
# CGPA and SOP: 91 support vectors
# CGPA and GRE: 86 support vectors
# SOP and LOR: 116 support vectors
# LOR and GRE: 126 support vectors

# RBF Kernel SVM:
# CGPA and SOP: 115 support vectors
# CGPA and GRE: 216 support vectors
# SOP and LOR: 118 support vectors
# LOR and GRE: 218 support vectors

# Poly (degree 3) Kernel SVM:
# CGPA and SOP: 83 support vectors
# CGPA and GRE: 126 support vectors
# SOP and LOR: 115 support vectors
# LOR and GRE: 126 support vectors
# PART E
def svm_predictions(model, X_train, y_train, features):
    model.fit(X_train[features], y_train)
    
    # create a grid 
    xcoord, ycoord = np.meshgrid(np.linspace(X_train[features[0]].min(), X_train[features[0]].max(), 500),
                         np.linspace(X_train[features[1]].min(), X_train[features[1]].max(), 500))
    
    # use the trained model to predict the class label for each point in the grid
    Z = model.predict(np.c_[xcoord.ravel(), ycoord.ravel()])
    Z = Z.reshape(xcoord.shape)
    
    # plot the contours on the grid
    plt.contourf(xcoord, ycoord, Z, alpha=0.5, cmap=plt.cm.coolwarm)
    
    # plot the training points
    scatter = plt.scatter(X_train[features[0]], X_train[features[1]], c=y_train, cmap=plt.cm.coolwarm)
    plt.xlabel(features[0])
    plt.ylabel(features[1])
    plt.show()

# for each kernel - input combination, visualize the predictions on the training set
print("Linear")
svm_predictions(linear, X_train, y_train, ['CGPA', 'SOP'])
svm_predictions(linear, X_train, y_train, ['CGPA', 'GRE Score'])
svm_predictions(linear, X_train, y_train, ['SOP', 'LOR '])
svm_predictions(linear, X_train, y_train, ['LOR ', 'GRE Score'])
print("RBF")
svm_predictions(rbf, X_train, y_train, ['CGPA', 'SOP'])
svm_predictions(rbf, X_train, y_train, ['CGPA', 'GRE Score'])
svm_predictions(rbf, X_train, y_train, ['SOP', 'LOR '])
svm_predictions(rbf, X_train, y_train, ['LOR ', 'GRE Score'])
print("Poly")
svm_predictions(poly, X_train, y_train, ['CGPA', 'SOP'])
svm_predictions(poly, X_train, y_train, ['CGPA', 'GRE Score'])
svm_predictions(poly, X_train, y_train, ['SOP', 'LOR '])
svm_predictions(poly, X_train, y_train, ['LOR ', 'GRE Score'])
# PART F
# The optimal models based on the provided validation score is the SVM with an RBF kernel
# for the feature combination CGPA and SOP. This achieved the highest validation accuracy.
# The RBF kernel typically creates more flexible decision boundaries, which can curve around
# data points, leading to better classification of non-linearly separable data. While other
# combinations were consistent, they had more overlap and did not exceed the RBF's effectiveness.
# PART G
best_features = ['CGPA', 'SOP']
best_model = SVC(kernel='rbf')
best_model.fit(X_train[best_features], y_train)

test_predictions = best_model.predict(test_data[best_features])

predictions_df = pd.DataFrame(test_predictions, columns=['Predictions'])

predictions_filename = "Manisha_Subrahmanya_preds.csv"
predictions_df.to_csv(predictions_filename, index=False)

print("saved to csv file")
