# PART A
# You may use pandas library and use read csv function
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

data_train = pd.read_csv('data_train.csv')    
data_test = pd.read_csv('data_test.csv')
print(data_train.head())       # Print the first 5 rows of the data using the command
print(data_train.shape)        # Print the shape of the training dataframe
print()
print("Short Description of Data: The training dataset contains 6250 records of air quality measurements, covering 13 different types of information such as pollution levels (like Benzene and Nitrogen Oxides), temperature, and humidity. Some data points are missing. This data is useful for creating computer models that can predict air quality. This data needs to be cleaned up before it can be used for predictions.")
print(data_train.isnull())          # checks to see if data has missing values
data_train.isnull().sum()     # total number of values missing
data_train = data_train.dropna()    # gets rid of the rows with missing data
data_train
x_train = data_train.drop('PT08.S1(CO)', axis=1)
# PART B
features = ['NMHC(GT)', 'C6H6(GT)', 'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)', 'PT08.S5(O3)', 'T', 'RH', 'AH']
for feature in features:
    plt.figure(figsize=(10, 4))  # Set the figure size
    plt.hist(data_train[feature], bins=30, edgecolor='k', alpha=0.7)  # Plot histogram
    plt.title(feature)  # Sets the title
    plt.xlabel(feature)  # x axis label
    plt.ylabel('Frequency')  # y axis label
    plt.show()  # Display the plot

plt.figure(figsize=(10, 6))
plt.scatter(x='PT08.S3(NOx)', y='NMHC(GT)', data=data_train)
plt.title('Plot between PT08.S3(NOx) and NMHC(GT)')
plt.xlabel('PT08.S3(NOx)')
plt.ylabel('NMHC(GT)')
plt.show()
# Compute the Pearsonâ€™s correlation matrix and visualize it
import seaborn as sb

pearson = data_train[features].corr()
plt.figure(figsize=(12, 10))
sb.heatmap(pearson, annot=True)
plt.title('Pearson Correlation')
plt.show()

# PART C
# # Implement a linear regression model from scratch to regress the target variable, Carbon monoxide (CO). (Remember: You can not
# # use any libraries for the linear regression model
  
def linearRegression(X, y, alpha, iterations):
    thetaLin = np.zeros(X.shape[1])        # Initialize theta
    thetaLin, cost_history = gradientDescent(X, y, thetaLin, alpha, iterations)
    return thetaLin, cost_history

def gradientDescent(X, y, thetaLin, alpha, iterations):
    m = len(y)
    costList = np.zeros(iterations)     # initialize cost
    
    for i in range(iterations):
        predictions = X.dot(thetaLin)
        errors = np.subtract(predictions, y)
        thetaLin = thetaLin - (alpha / m) * X.transpose().dot(errors);     # computes theta values
        costList[i] = costFunction(X, y, thetaLin)
        
    return thetaLin, costList

def costFunction(X, y, thetaLin):
    m = len(y)
    predictions = X.dot(thetaLin)       # predicts y value
    cost = (np.sum(predictions - y) ** 2) / (2 * m)     # compute the cost
    return cost

features = data_train.drop(columns=['PT08.S1(CO)', 'Unnamed: 0'])
y = data_train['PT08.S1(CO)'].values      # actual values
m = len(y)

mean = features.mean(axis=0)
std = features.std(axis=0)
featuresNormal = (features - mean) / std

X = np.c_[np.ones((featuresNormal.shape[0], 1)), featuresNormal.values]     # adds a column of ones to X matrix

thetaLin = np.zeros(X.shape[1])    # initialize column vector (n x 1) theta to all zeroes

alpha = 0.01      # smaller the better, if too big it will exceed
iterations = 1000

thetaLin, currentCost = linearRegression(X, y, alpha, iterations)

print("theta value at the end of this section is", thetaLin)
# PART D
# Using the column PT08.S1(CO),
# create a binary label for this dataset where the values more than 1000 correspond to label 1
# and the values less than or equal to 1000 correspond to label 0. Implement a logistic regression
# model from scratch to predict this binary label. (Remember: You can not use any libraries
# for the logistic regression model.)

data_train['BinaryLabel'] = np.where(data_train['PT08.S1(CO)'] > 1000, 1, 0)         # create binary labels based on the condition provided
y = data_train['BinaryLabel'].values

features = data_train.drop(columns=['PT08.S1(CO)', 'BinaryLabel', 'Unnamed: 0'])    # exclude 'PT08.S1(CO)' and 'BinaryLabel'

mean = features.mean()             
std = features.std()
featuresNormal = (features - mean) / std          # normalize features to bring them to a common scale without distorting their differences

X = np.c_[np.ones(featuresNormal.shape[0]), featuresNormal]        # add a column of ones to X

def sigmoid(z):                          # logistic regression model
    return 1 / (1 + np.exp(-z))

def logisticRegression(X, y, alpha, iterations):
    thetaLogi = np.zeros(X.shape[1])       # initialize to zero
    for reg in range(iterations):
        z = np.dot(X, thetaLogi)    # each element represents the linear combination of the features     
        predictions = sigmoid(z)    # gives predictions as probabilities bw 0 and 1
        errors = y - predictions      # calculates the difference between predicted value and actual value
        updates = np.dot(X.T, errors)        # gradient of loss function
        
        thetaLogi = thetaLogi + (alpha * updates / len(y))
        
    return thetaLogi

alpha = 0.01  # Learning rate
iterations = 1000 

thetaLogi = logisticRegression(X, y, alpha, iterations)

def predict(X, thetaLogi):
    probabilities = sigmoid(np.dot(X, thetaLogi))
    return probabilities >= 0.5

print("Theta coefficients:", thetaLogi)
# print("Predictions on test data:", predictions)

# PART E
# print("theta at the beginning is", thetaLin)

def calculateRMSE(predictions, targets):
    return np.sqrt(np.mean((predictions - targets) ** 2))    # root-mean-square

# redefining features and target
features = data_train.drop(columns=['Unnamed: 0', 'PT08.S1(CO)'])
target = data_train['PT08.S1(CO)']

mean = features.mean()
std = features.std()
features_normalized = (features - mean) / std           # normalize features to bring them to a common scale without distorting their differences

X = np.c_[np.ones((features_normalized.shape[0], 1)), features_normalized]   # add column of ones
y = target.values

alpha = 0.01
iterations = 1000

k = 5        # 5 fold cross validation 
fold_size = len(X) // k
rmse = []

for i in range(k):
    start = i * fold_size
    end = start + fold_size
    
    X_test = X[start:end]    # creating the test set by slicing data set
    y_test = y[start:end]    # keeping added fold_size to the length to create next data set eg: 0-5, 6-11, 12-17 etc
    X_train = np.concatenate([X[:start], X[end:]])    # make one big training set from all the remaining blocks
    y_train = np.concatenate([y[:start], y[end:]])    # make one big training set from all the remaining blocks
    
    theta, _cost = linearRegression(X_train, y_train, alpha, iterations)
#     print("theta at", i, "is", theta)
    
    predictions = X_test.dot(theta)     # predicting y for the test block
    
    rmseVal = calculateRMSE(predictions, y_test)     # calculating the rmse value
    rmse.append(rmseVal)

print("Average RMSE:", np.mean(rmse))
print("Standard Deviation of RMSE:", np.std(rmse))

# PART F
# confusion matrix
def confusionMatrix(actualy, predicty):
    truePos = np.sum((actualy == 1) & (predicty == 1))
    trueNeg = np.sum((actualy == 0) & (predicty == 0))
    falsePos = np.sum((actualy == 0) & (predicty == 1))
    falseNeg = np.sum((actualy == 1) & (predicty == 0))
    
    accuracy = (truePos + trueNeg) / len(actualy)
    precision = truePos / (truePos + falsePos) if truePos + falsePos > 0 else 0
    recall = truePos / (truePos + falseNeg) if truePos + falseNeg > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0
    
    return accuracy, precision, recall, f1

features = data_train.drop(columns=['Unnamed: 0', 'PT08.S1(CO)'])
y = np.where(data_train['PT08.S1(CO)'] > 1000, 1, 0)   # binary classification based on the condition

mean = features.mean()
std = features.std()
normalFeatures = (features - mean) / std
X = np.c_[np.ones((normalFeatures.shape[0], 1)), normalFeatures]        # normalize features to bring them to a common scale without distorting their differences

alpha = 0.01
iterations = 1000

k = 5    # five fold
fold_size = len(X) // k
confusion = []

for i in range(k):
    start = i * fold_size          
    end = start + fold_size
    
    X_test = X[start:end]       # creating the test set by slicing data set
    y_test = y[start:end]         # keeping added fold_size to the length to create next data set eg: 0-5, 6-11, 12-17 etc
    X_train = np.concatenate([X[:start], X[end:]])        # make one big training set from all the remaining blocks
    y_train = np.concatenate([y[:start], y[end:]])   # make one big training set from all the remaining blocks

    theta = logisticRegression(X_train, y_train, alpha, iterations)
    
    ztest = np.dot(X_test, theta)
    predictions = sigmoid(ztest) >= 0.5
    
    accuracy, precision, recall, f1 = confusionMatrix(y_test, predictions)
    confusion.append((accuracy, precision, recall, f1))

accuracies, precisions, recalls, f1s = zip(*confusion)       # unpacks list into separate variables i.e. makes a tuple of lists
print("Average Accuracy:", np.mean(accuracies))
print("Average Precision:", np.mean(precisions))
print("Average Recall:", np.mean(recalls))
print("Average F1 Score:", np.mean(f1s))

# PART G
from sklearn.model_selection import KFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, auc
 
kf = KFold(n_splits=5)       # 5 fold

plt.figure(figsize=(10, 8))
areaCurve = []

# Perform 5-fold cross-validation
for test_index, train_index in kf.split(X):
    X_train = X[train_index]
    Xval = X[test_index]
    y_train = y[train_index] 
    yval = y[test_index]
    
    model = LogisticRegression(max_iter=1000, solver='lbfgs')
    model.fit(X_train, y_train)     # fit model into training data
    
    predy = model.predict_proba(Xval)[:, 1]     # predict if value will be positive
    
    falsePos, truePos, _ = roc_curve(yval, predy)  
    areaVal = auc(falsePos, truePos)     # calculates area under curve
    areaCurve.append(areaVal)
    
    plt.plot(falsePos, truePos, label=f'Fold {len(areaCurve)} (AUC = {areaVal})')

plt.plot([0, 1], [0, 1], 'k--', lw=2, color='gray', label='Chance')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves for 5-Fold Cross-Validation')
plt.legend(loc="lower right")
plt.show()

print("AUC values for each Fold:", areaCurve)

# PART H
# 1. Use the trained linear regression model and predict the PT08.S1(CO) value for the test
# data.
# 2. Use the trained logistic regression model and predict the PT08.S1(CO) binary value (the
# same label you created in step d) for the test data.
# 3. Save the predictions in a csv file with two main columns. One for the linear regression
# predictions with the name pred linear and one for the logistic regression predictions with
# the name pred logistic.
# 4. Add this csv file to your submission.

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

features = data_train.drop(columns=['Unnamed: 0', 'PT08.S1(CO)']) 

features_test = data_train.drop(columns=['Unnamed: 0', 'PT08.S1(CO)'])
X_test = np.c_[np.ones((features_test.shape[0], 1)), features_test]      # add a column of ones

thetaLin = np.random.rand(X_test.shape[1])      # breaks symmetry
thetaLogi = np.random.rand(X_test.shape[1]) 

pred_linear = np.dot(X_test, thetaLin)

pred_logistic = sigmoid(np.dot(X_test, thetaLogi))
pred_logistic = (pred_logistic >= 0.5).astype(int)

predDataFrame = pd.DataFrame({
    'pred_linear': pred_linear, 
    'pred_logistic': pred_logistic
})

predDataFrame.to_csv('Manisha_Subrahmanya_preds.csv', index=False)

# print("HW1.csv")


